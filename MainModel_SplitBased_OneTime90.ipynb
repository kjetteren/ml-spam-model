{
 "cells": [
  {
   "cell_type": "code",
   "id": "d5e70c52",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#*****************************************Import********************************************\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "df=pd.read_csv(\"dataset/PhishingDataset.csv\")\n",
    "\n",
    "ROWS = len(df.axes[0]) \n",
    "COLUMNS = len(df.axes[1])\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df=df.dropna()\n",
    "LABEL = df.iloc[:,-1:].columns[0]\n",
    "\n",
    "\n",
    "print(\"Row-Column Count before cleaning: (\", ROWS , \" , \",  COLUMNS , \")\")\n",
    "\n",
    "df.iloc[:,-1:].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ba9e2509",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#cols = df.select_dtypes(include=['float64','int64']).columns\n",
    "#dfAll = pd.DataFrame(df['FILENAME']).copy()\n",
    "#df = pd.DataFrame(df[cols]).copy()\n",
    "df = df.reset_index(drop=True)\n",
    "LABEL = df.iloc[:,-1:].columns[0]\n",
    "cols = ['LineOfCode', 'NoOfExternalRef', 'LargestLineLength', 'URLLength', 'NoOfImage', 'NoOfJS', 'NoOfSelfRef', 'NoOfCSS', \n",
    "        'URLCharProb', 'CharContinuationRate', 'LetterRatioInURL', 'IsHTTPS', 'SpacialCharRatioInURL','NoOfEmptyRef', \n",
    "        'NoOfOtherSpecialCharsInURL', 'HasDescription', 'HasSocialNet', 'DomainLength', 'DegitRatioInURL','NoOfDegitsInURL',\n",
    "        'HasCopyrightInfo', 'NoOfLettersInURL','TLDLegitimateProb', 'DomainTitleMatchScore', 'IsResponsive', \n",
    "        'HasHiddenFields', 'HasSubmitButton','NoOfSubDomain', 'HasFavicon', 'HasTitle',LABEL]\n",
    "df = pd.DataFrame(df[cols]).copy()\n",
    "df30, df70=train_test_split(df,test_size=.1)\n",
    "\n",
    "df30 = df30.reset_index(drop=True)\n",
    "df70 = df70.reset_index(drop=True)\n",
    "\n",
    "yTrain = pd.DataFrame(df30[LABEL]).copy()\n",
    "df30.drop(LABEL, axis=1, inplace=True)\n",
    "xTrain = pd.DataFrame(df30).copy()\n",
    "\n",
    "dfX = pd.DataFrame(df70[cols]).copy()\n",
    "dfX.drop(LABEL, axis=1, inplace=True)\n",
    "dfY = pd.DataFrame(df70[LABEL]).copy()\n",
    "print(\"Finished Train-Test Split.\")\n",
    "len(xTrain.axes[0]) "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3958e2c5",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "Models = []\n",
    "Models.append((\"BernoulliNB\",BernoulliNB(alpha= 0.01, binarize= 0.0, class_prior= None, fit_prior= False, force_alpha= True)))\n",
    "Models.append((\"PassiveAggressive\",PassiveAggressiveClassifier(C= 4, fit_intercept= False, n_iter_no_change= 50, n_jobs= 10, shuffle= True, verbose= 0)))\n",
    "Models.append((\"SGDClassifier\",SGDClassifier(alpha= 0.01, eta0= 100, n_iter_no_change= 50, n_jobs= 1)))\n",
    "\n",
    "start = time.time()\n",
    "for name, model in Models:\n",
    "    model.fit(xTrain, yTrain)\n",
    "end = time.time()\n",
    "OneTime = int(end - start)\n",
    "print(\"Finished first training: \", OneTime)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e5fa1a44",
   "metadata": {},
   "source": [
    "Handler = pd.DataFrame(columns=['BernoulliNB','PassiveAggressive','SGDClassifier', 'sum','isCorrect','predicted',\n",
    "                                'label','LowSecurity','BestSecurity','HighSecurity','LearningRate','AverageLearningRate'])\n",
    "LRList = []\n",
    "AvgLRList = []\n",
    "n = len(dfX.axes[0])\n",
    "X = dfX.iloc[[0]].to_numpy() \n",
    "Y = dfY.iloc[[0]]\n",
    "Y = np.array(Y[LABEL])\n",
    "p = len(Models)    \n",
    "accurate=0\n",
    "start = time.time()\n",
    "for i in range(0,n):\n",
    "    try:\n",
    "        X = dfX.iloc[[i]].to_numpy() \n",
    "        Y = dfY.iloc[[i]]\n",
    "        Y = np.array(Y[LABEL])\n",
    "        predict=0\n",
    "        yP=0\n",
    "        nRow = {}\n",
    "        nRow['isCorrect'] = 0\n",
    "        nRow['LowSecurity'] = 0\n",
    "        nRow['BestSecurity'] = 0\n",
    "        nRow['HighSecurity'] = 0\n",
    "        \n",
    "        for name, model in Models:\n",
    "            pr = model.predict(X)\n",
    "            predict = predict + pr[0]\n",
    "            model.partial_fit(X, Y, classes=[0,1])\n",
    "            if(pr[0]==Y[0]):\n",
    "                nRow[name] = 1\n",
    "            else:\n",
    "                nRow[name] = 0\n",
    "\n",
    "        if (predict==1):\n",
    "            nRow['LowSecurity'] = 1\n",
    "        elif (predict==2):\n",
    "            yP = 1\n",
    "            nRow['LowSecurity'] = 1\n",
    "            nRow['BestSecurity'] = 1\n",
    "        elif (predict==3):\n",
    "            yP = 1\n",
    "            nRow['LowSecurity'] = 1\n",
    "            nRow['BestSecurity'] = 1\n",
    "            nRow['HighSecurity'] = 1\n",
    "            \n",
    "            \n",
    "        if(yP==Y[0]):\n",
    "            accurate = accurate + 1\n",
    "            nRow['isCorrect'] = 1\n",
    "        elif(i%250==0): \n",
    "            print(i)\n",
    "        nRow['sum'] = predict\n",
    "        nRow['predicted'] = yP\n",
    "        nRow['label'] = Y[0]\n",
    "          \n",
    "        LearnRate=accurate/n\n",
    "        AvgLearnRate=accurate/(i+1)\n",
    "        LRList.append(LearnRate)\n",
    "        AvgLRList.append(AvgLearnRate)\n",
    "        \n",
    "        nRow['LearningRate'] = LearnRate\n",
    "        nRow['AverageLearningRate'] = AvgLearnRate\n",
    "\n",
    "        Handler = pd.concat([Handler, pd.DataFrame([nRow])], ignore_index=True)\n",
    "        \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "end = time.time()\n",
    "IncTime = int(end - start)\n",
    "# Handler.to_csv('dataset/ReportsPhishing/Model_Result_29May_90.csv',index = False)\n",
    "print('Time:', IncTime, ' Accuracy:',accurate/n)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd180900",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(LRList)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "64daa05b",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(AvgLRList)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "223c90ad",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(AvgLRList)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "212ddb54",
   "metadata": {},
   "source": [
    "ResAnalysis = pd.DataFrame(columns=['yTest']).copy()\n",
    "ResAnalysis['yTest'] = Handler['label']\n",
    "ResAnalysis['M1Vote'] = Handler['LowSecurity']\n",
    "ResAnalysis['M1rTP'] = np.where(ResAnalysis['yTest'] == 1, \n",
    "                                   np.where(Handler['LowSecurity']==1, 1, 0), 0)\n",
    "ResAnalysis['M1rTN'] = np.where(ResAnalysis['yTest'] == 0, \n",
    "                                   np.where(Handler['LowSecurity']==0, 1, 0), 0)\n",
    "ResAnalysis['M1rFP'] = np.where(ResAnalysis['yTest'] == 0, \n",
    "                                   np.where(Handler['LowSecurity']==1, 1, 0), 0)\n",
    "ResAnalysis['M1rFN'] = np.where(ResAnalysis['yTest'] == 1, \n",
    "                                   np.where(Handler['LowSecurity']==0, 1, 0), 0)\n",
    "\n",
    "records = len(ResAnalysis['yTest'])\n",
    "CorretPred = np.where(ResAnalysis['yTest'] == ResAnalysis['M1Vote'], 1, 0).sum()\n",
    "TP = int(ResAnalysis['M1rTP'].sum())\n",
    "TN = int(ResAnalysis['M1rTN'].sum())\n",
    "FP = int(ResAnalysis['M1rFP'].sum())\n",
    "FN = int(ResAnalysis['M1rFN'].sum())\n",
    "print(TP, ' ' , TN, ' ', FP,' ', FN)\n",
    "\n",
    "MCC = int((TP*TN)-(FP*FN))/(int((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**0.5)\n",
    "\n",
    "Accuracy = CorretPred/records\n",
    "Precision = TP/(TP+FP)\n",
    "Sensitivity = TP/(TP+FN)\n",
    "F1Score = 2* ((Precision*Sensitivity)/(Precision+Sensitivity))\n",
    "\n",
    "\n",
    "print(\"Accuracy    : \", Accuracy)\n",
    "print(\"Precision   : \", Precision)\n",
    "print(\"Sensitivity : \", Sensitivity)\n",
    "print(\"F1 Score    : \", F1Score )\n",
    "print(\"MCC    : \", MCC )\n",
    "\n",
    "Metrics= pd.DataFrame()\n",
    "newRow = {}\n",
    "newRow['Mode'] = \"LowSecurity\"\n",
    "newRow['Accuracy'] = Accuracy\n",
    "newRow['Precision'] = Precision\n",
    "newRow['Sensitivity'] = Sensitivity\n",
    "newRow['F1Score'] = F1Score\n",
    "newRow['MCC'] = MCC\n",
    "newRow['OneTime'] = OneTime\n",
    "newRow['IncTime'] = IncTime\n",
    "Metrics = pd.concat([Metrics, pd.DataFrame([newRow])], ignore_index=True)\n",
    "\n",
    "CM= pd.DataFrame()\n",
    "newRow = {}\n",
    "newRow['Mode'] = \"LowSecurity\"\n",
    "newRow['TP'] = TP\n",
    "newRow['TN'] = TN\n",
    "newRow['FP'] = FP\n",
    "newRow['FN'] = FN\n",
    "CM = pd.concat([CM, pd.DataFrame([newRow])], ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8061ee5b",
   "metadata": {},
   "source": [
    "ResAnalysis = pd.DataFrame(columns=['yTest']).copy()\n",
    "ResAnalysis['yTest'] = Handler['label']\n",
    "ResAnalysis['M2Vote'] = Handler['BestSecurity']\n",
    "ResAnalysis['M2rTP'] = np.where(ResAnalysis['yTest'] == 1, \n",
    "                                   np.where(Handler['BestSecurity']==1, 1, 0), 0)\n",
    "ResAnalysis['M2rTN'] = np.where(ResAnalysis['yTest'] == 0, \n",
    "                                   np.where(Handler['BestSecurity']==0, 1, 0), 0)\n",
    "ResAnalysis['M2rFP'] = np.where(ResAnalysis['yTest'] == 0, \n",
    "                                   np.where(Handler['BestSecurity']==1, 1, 0), 0)\n",
    "ResAnalysis['M2rFN'] = np.where(ResAnalysis['yTest'] == 1, \n",
    "                                   np.where(Handler['BestSecurity']==0, 1, 0), 0)\n",
    "\n",
    "records = len(ResAnalysis['yTest'])\n",
    "CorretPred = np.where(ResAnalysis['yTest'] == ResAnalysis['M2Vote'], 1, 0).sum()\n",
    "TP = int(ResAnalysis['M2rTP'].sum())\n",
    "TN = int(ResAnalysis['M2rTN'].sum())\n",
    "FP = int(ResAnalysis['M2rFP'].sum())\n",
    "FN = int(ResAnalysis['M2rFN'].sum())\n",
    "print(TP, ' ' , TN, ' ', FP,' ', FN)\n",
    "\n",
    "MCC = int((TP*TN)-(FP*FN))/(int((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**0.5)\n",
    "\n",
    "Accuracy = CorretPred/records\n",
    "Precision = TP/(TP+FP)\n",
    "Sensitivity = TP/(TP+FN)\n",
    "F1Score = 2* ((Precision*Sensitivity)/(Precision+Sensitivity))\n",
    "\n",
    "\n",
    "print(\"Accuracy    : \", Accuracy)\n",
    "print(\"Precision   : \", Precision)\n",
    "print(\"Sensitivity : \", Sensitivity)\n",
    "print(\"F1 Score    : \", F1Score )\n",
    "print(\"MCC    : \", MCC )\n",
    "\n",
    "newRow = {}\n",
    "newRow['Mode'] = \"BestSecurity\"\n",
    "newRow['Accuracy'] = Accuracy\n",
    "newRow['Precision'] = Precision\n",
    "newRow['Sensitivity'] = Sensitivity\n",
    "newRow['F1Score'] = F1Score\n",
    "newRow['MCC'] = MCC\n",
    "newRow['OneTime'] = OneTime\n",
    "newRow['IncTime'] = IncTime\n",
    "Metrics = pd.concat([Metrics, pd.DataFrame([newRow])], ignore_index=True)\n",
    "\n",
    "newRow = {}\n",
    "newRow['Mode'] = \"BestSecurity\"\n",
    "newRow['TP'] = TP\n",
    "newRow['TN'] = TN\n",
    "newRow['FP'] = FP\n",
    "newRow['FN'] = FN\n",
    "CM = pd.concat([CM, pd.DataFrame([newRow])], ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cae34d02",
   "metadata": {},
   "source": [
    "ResAnalysis = pd.DataFrame(columns=['yTest']).copy()\n",
    "ResAnalysis['yTest'] = Handler['label']\n",
    "ResAnalysis['M3Vote'] = Handler['HighSecurity']\n",
    "ResAnalysis['M3rTP'] = np.where(ResAnalysis['yTest'] == 1, \n",
    "                                   np.where(Handler['HighSecurity']==1, 1, 0), 0)\n",
    "ResAnalysis['M3rTN'] = np.where(ResAnalysis['yTest'] == 0, \n",
    "                                   np.where(Handler['HighSecurity']==0, 1, 0), 0)\n",
    "ResAnalysis['M3rFP'] = np.where(ResAnalysis['yTest'] == 0, \n",
    "                                   np.where(Handler['HighSecurity']==1, 1, 0), 0)\n",
    "ResAnalysis['M3rFN'] = np.where(ResAnalysis['yTest'] == 1, \n",
    "                                   np.where(Handler['HighSecurity']==0, 1, 0), 0)\n",
    "\n",
    "records = len(ResAnalysis['yTest'])\n",
    "CorretPred = np.where(ResAnalysis['yTest'] == ResAnalysis['M3Vote'], 1, 0).sum()\n",
    "TP = int(ResAnalysis['M3rTP'].sum())\n",
    "TN = int(ResAnalysis['M3rTN'].sum())\n",
    "FP = int(ResAnalysis['M3rFP'].sum())\n",
    "FN = int(ResAnalysis['M3rFN'].sum())\n",
    "print(TP, ' ' , TN, ' ', FP,' ', FN)\n",
    "\n",
    "MCC = int((TP*TN)-(FP*FN))/(int((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**0.5)\n",
    "\n",
    "Accuracy = CorretPred/records\n",
    "Precision = TP/(TP+FP)\n",
    "Sensitivity = TP/(TP+FN)\n",
    "F1Score = 2* ((Precision*Sensitivity)/(Precision+Sensitivity))\n",
    "\n",
    "\n",
    "print(\"Accuracy    : \", Accuracy)\n",
    "print(\"Precision   : \", Precision)\n",
    "print(\"Sensitivity : \", Sensitivity)\n",
    "print(\"F1 Score    : \", F1Score )\n",
    "print(\"MCC    : \", MCC )\n",
    "\n",
    "newRow = {}\n",
    "newRow['Mode'] = \"HighSecurity\"\n",
    "newRow['Accuracy'] = Accuracy\n",
    "newRow['Precision'] = Precision\n",
    "newRow['Sensitivity'] = Sensitivity\n",
    "newRow['F1Score'] = F1Score\n",
    "newRow['MCC'] = MCC\n",
    "newRow['OneTime'] = OneTime\n",
    "newRow['IncTime'] = IncTime\n",
    "Metrics = pd.concat([Metrics, pd.DataFrame([newRow])], ignore_index=True)\n",
    "\n",
    "newRow = {}\n",
    "newRow['Mode'] = \"HighSecurity\"\n",
    "newRow['TP'] = TP\n",
    "newRow['TN'] = TN\n",
    "newRow['FP'] = FP\n",
    "newRow['FN'] = FN\n",
    "CM = pd.concat([CM, pd.DataFrame([newRow])], ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35dd8b9d",
   "metadata": {},
   "source": [
    "Metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ea5d92d",
   "metadata": {},
   "source": [
    "CM"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
